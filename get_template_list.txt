UI will pass a path such as “/na/usa/fhc”

Syntax for the path is /na/{country}/{category} This syntax will match the syntax of where the files are located in the COST bucket

API will return the list of files located in the GCS cost bucket with the above path.

Path in GCS should be namespaced by environment. For example, DEV should have a prefix of /dev/na/usa/fhc

Pass (Category and country) and retrieve the list of tempelate

Array of string

JSON format

Below is the confluence link

version: '3'
name: ltvo-backend

services:
  psql-db:
    image: postgres:13
    container_name: psql-db
    environment:
      POSTGRES_USER: ltvo_ui_dev
      POSTGRES_PASSWORD: password123
    hostname: psql-db
    ports:
      - "5432:5432"
    volumes:
      - local_pgdata:/var/lib/postgresql/data
  gcp_storage:
    image: oittaa/gcp-storage-emulator
    container_name: gcp_storage
    ports:
      - "9023:9023"
    environment:
      PORT: 9023
      HOST: gcp_storage
    volumes:
      - gcp-data:/storage
  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin4_container
    restart: always
    ports:
      - "8888:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: test@pg.com
      PGADMIN_DEFAULT_PASSWORD: pass123
    volumes:
      - pgadmin-data:/var/lib/pgadmin
  api:
    container_name: ltvo_api
    build:
      context: ..
      dockerfile: setup/Dockerfile
    image: ltvo-backend
    environment:
      - ACTIVE_PROFILE=LOCAL
      - PG_HOST=psql-db:5432
      - PG_USER=ltvo_ui_dev
      - PG_PASSWORD=password123
      - FLASK_ENV=development
      - FLASK_APP=app
      - STORAGE_EMULATOR_HOST=http://gcp_storage:9023
    entrypoint: /ltvo-backend/setup/entrypoint.sh
    ports:
      - "9090:9090"
    volumes:
      - ..:/ltvo-backend
    depends_on:
      - psql-db

volumes:
  local_pgdata:
  pgadmin-data:
  gcp-data:

GET COST FILE
UI will pass a path such as “/na/usa/fhc/FHC_UNCONSTRAINED”

syntax is /na/{country}/{category}/{template}

API must validate the user has access to the country / category for which they are calling the endpoint. Can use legacy API functionality for this validation.

API must return the json list of deals that are in the csv file at the above path


gcp_storage:
    image: oittaa/gcp-storage-emulator
    container_name: gcp_storage
    ports:
      - "9023:9023"
    environment:
      PORT: 9023
      HOST: gcp_storage
    volumes:
      - gcp-data:/storage



 source_blob = storage_client.list_blobs(bucket, prefix=prefix, delimiter="/")
        copied_list = []
        for blob in source_blob:
            if blob.name.endswith(".csv"):
                source_bucket.copy_blob(blob, destination_bucket, dest_path + blob.name.split("/")[-1])
                copied_list.append({"file_copied" : bucket + "/"+ dest_path + blob.name.split("/")[-1]})
        return copied_list

BUCKET_NAME = 'ltvo-dswb-prod-c423-ltvo-us-t4p8zaot'
if country not in generate_fn: 
        return {
            'message': f"Country {country} not supported."
        }, http.HTTPStatus.NOT_FOUND
    
    storage_client = storage.Client()
    bucket_name = BUCKET_NAME # param from config
    blob_name = 'ESM_STG/' + country + '/' + template + '.csv' 
    
    bucket = storage_client.get_bucket(bucket_name)
    blob = bucket.get_blob(blob_name)
    if not blob: return



import os
from google.cloud import storage
from flask import Flask, request, jsonify

app = Flask(__name__)

def get_file_names(country, template):
    # Get the bucket name from the environment variable
    bucket_name = os.environ.get('GCS_BUCKET_NAME')

    if not bucket_name:
        return {"error": "GCS_BUCKET_NAME environment variable not set."}

    storage_client = storage.Client()

    # Construct the blob prefix
    blob_prefix = f'ESM_STG/{country}/{template}/'

    # Get the bucket
    bucket = storage_client.bucket(bucket_name)

    # List blobs in the bucket with the specified prefix
    blobs = list(bucket.list_blobs(prefix=blob_prefix))

    file_names = [blob.name.split("/")[-1] for blob in blobs]

    return file_names

@app.route('/get_file_names', methods=['GET'])
def get_file_names_endpoint():
    try:
        # Get parameters from the request
        country = request.args.get('country')
        template = request.args.get('template')

        # Check if required parameters are provided
        if not country or not template:
            return jsonify({"error": "Missing required parameters."}), 400

        # Get file names from the GCS path
        file_names = get_file_names(country, template)

        return jsonify({"file_names": file_names})

    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)


 metadata server.
ltvo_api            | INFO:werkzeug:172.22.0.1 - - [03/Jan/2024 17:25:01] "GET /api/v2/cost_file_names?country=USA&category=FHC HTTP/1.1" 500 -
ltvo_api            | WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
ltvo_api            | WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
ltvo_api            | WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
ltvo_api            | WARNING:google.auth._default:Authentication failed using Compute Engine authentication due to unavailable metadata server.

api.add_resource(CostFileResource, '/api/v2/cost_file')
api.add_resource(CostFileResource, '/api/v2/cost_file_names')
api.add_resource(OptimizationRunListResource, '/api/v2/optimization_runs')
api.add_resource(DevOptimizationsResource, '/api/v2/dev_optimization/list')
api.add_resource(OptimizationRunResource, *optimization_run_routes)



from google.cloud._helpers import _NOW

def create_anonymous_client(*args, **kwargs):
    creds = AnonymousCredentials()
    if _NOW() > creds.expiry:
        creds.refresh(Request())
    return storage.Client(credentials=creds, _http=grpc.Request())
'


country=input("Enter country name")
category=input("Enter category name")
from google.cloud import storage
storage_client=storage.Client()

bucket_name="dbce-ltvo-ui-dev-16d3-ltvo-ui-cf-2q88ktf9"
print(bucket_name)

blob_prefix=f"/{country}/{category}/"

bucket = storage_client.bucket(bucket_name)

blobs=list(bucket.list_blobs(prefix=blob_prefix))

file_names=[blob.name.split("/")[-1] for blob in blobs]

print(file_names)


Traceback (most recent call last):
  File "/home/subash_vo/sample.py", line 12, in <module>
    blobs=list(bucket.list_blobs(prefix=blob_prefix))
  File "/usr/local/lib/python3.9/dist-packages/google/api_core/page_iterator.py", line 208, in _items_iter
    for page in self._page_iter(increment=False):
  File "/usr/local/lib/python3.9/dist-packages/google/api_core/page_iterator.py", line 244, in _page_iter
    page = self._next_page()
  File "/usr/local/lib/python3.9/dist-packages/google/api_core/page_iterator.py", line 373, in _next_page
    response = self._get_next_page_response()
  File "/usr/local/lib/python3.9/dist-packages/google/api_core/page_iterator.py", line 432, in _get_next_page_response
    return self.api_request(
  File "/usr/local/lib/python3.9/dist-packages/google/cloud/storage/_http.py", line 72, in api_request
    return call()
  File "/usr/local/lib/python3.9/dist-packages/google/api_core/retry.py", line 372, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.9/dist-packages/google/api_core/retry.py", line 207, in retry_target
    result = target()
  File "/usr/local/lib/python3.9/dist-packages/google/cloud/_http/__init__.py", line 482, in api_request
    response = self._make_request(
  File "/usr/local/lib/python3.9/dist-packages/google/cloud/_http/__init__.py", line 341, in _make_request
    return self._do_request(
  File "/usr/local/lib/python3.9/dist-packages/google/cloud/_http/__init__.py", line 379, in _do_request
    return self.http.request(
  File "/usr/local/lib/python3.9/dist-packages/google/auth/transport/requests.py", line 537, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/usr/local/lib/python3.9/dist-packages/google/auth/credentials.py", line 175, in before_request
    self.refresh(request)
  File "/usr/local/lib/python3.9/dist-packages/google/auth/compute_engine/credentials.py", line 116, in refresh
    self._retrieve_info(request)
  File "/usr/local/lib/python3.9/dist-packages/google/auth/compute_engine/credentials.py", line 93, in _retrieve_info
    self._service_account_email = info["email"]
TypeError: string indices must be integers



[['name', 'age', 'gender'], ['subash', '23', 'male']]



country=input("Enter country name")
category=input("Enter category name")
from google.cloud import storage
storage_client=storage.Client()

bucket_name="dbce-ltvo-ui-dev-16d3-ltvo-ui-cf-2q88ktf9"
print(bucket_name)
blob_prefix=f"ltvo_dev/na/{country}/{category}"
#print("dbce-ltvo-ui-dev-16d3-ltvo-ui-cf-2q88ktf9/ltvo_dev/na/usa/fhc")
bucket = storage_client.bucket(bucket_name)

blobs=list(bucket.list_blobs(prefix=blob_prefix))
file_names=[blob.name.split("/")[-1] for blob in blobs]
print(file_names)


Traceback (most recent call last):
  File "/usr/local/lib/python3.9/dist-packages/google/cloud/storage/blob.py", line 4332, in _prep_and_do_download
    self._do_download(
  File "/usr/local/lib/python3.9/dist-packages/google/cloud/storage/blob.py", line 987, in _do_download
    response = download.consume(transport, timeout=timeout)
  File "/usr/local/lib/python3.9/dist-packages/google/resumable_media/requests/download.py", line 237, in consume
    return _request_helpers.wait_and_retry(
  File "/usr/local/lib/python3.9/dist-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
  File "/usr/local/lib/python3.9/dist-packages/google/resumable_media/requests/download.py", line 219, in retriable_request
    self._process_response(result)
  File "/usr/local/lib/python3.9/dist-packages/google/resumable_media/_download.py", line 188, in _process_response
    _helpers.require_status_code(
  File "/usr/local/lib/python3.9/dist-packages/google/resumable_media/_helpers.py", line 108, in require_status_code




for csv_file in csv_file_names:
    print(f"\nProcessing CSV file:{csv_file}")
    print(csv_file)
    file = bucket.blob(csv_file)
    print(file.exists())
    
    try:
        # blob=bucket.blob(csv_file)
        # content=blob.download_as_text()
        # print(content)
        blob_name=csv_file
        blob = bucket.blob(blob_name)
        rows = blob.download_as_bytes().decode().splitlines()
        rows_list=list(csv.reader(rows))
        print(list(csv.reader(rows)))
        print(rows_list[0])
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/subash_vo/sample.py", line 21, in <module>
    content=blob.download_as_text()
  File "/usr/local/lib/python3.9/dist-packages/google/cloud/storage/blob.py", line 1630, in download_as_text
    data = self.download_as_bytes(
  File "/usr/local/lib/python3.9/dist-packages/google/cloud/storage/blob.py", line 1405, in download_as_bytes
    self._prep_and_do_download(
  File "/usr/local/lib/python3.9/dist-packages/google/cloud/storage/blob.py", line 4345, in _prep_and_do_download
    _raise_from_invalid_response(exc)
  File "/usr/local/lib/python3.9/dist-packages/google/cloud/storage/blob.py", line 4791, in _raise_from_invalid_response
    raise exceptions.from_http_status(response.status_code, message, response=response)
google.api_core.exceptions.NotFound: 404 GET https://storage.googleapis.com/download/storage/v1/b/dbce-ltvo-ui-dev-16d3-ltvo-ui-cf-2q88ktf9/o/sample1.csv?alt=media: No such object: dbce-ltvo-ui-dev-16d3-ltvo-ui-cf-2q88ktf9/sample1.csv: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)
subash_vo@cloudshell:~$ 



 header = rows[0].split(',')
        
        # Create a list of dictionaries
        data_list = []
        for row in rows[1:]:
            row_values = row.split(',')
            data_dict = {header[i]: row_values[i] for i in range(len(header))}
            data_list.append(data_dict)
        
        # Print the list of dictionaries
        print(data_list)
        
        # Convert the list to JSON
        json_data = json.dumps(data_list, indent=2)
        print(json_data)




def get_csv_file_names(country,category):
    storage_client=storage.Client()
    bucket_name=get_app_configs().get(ESM_GCS_BUCKET)
    ns=get_app_configs().get(NAMESPACE)
    blob_prefix=f"ltvo_{ns}/na/{country}/{category}"
    bucket = storage_client.bucket(bucket_name)
    blobs=list(bucket.list_blobs(prefix=blob_prefix))
    csv_file_names=[blob.name for blob in blobs if blob.name.lower().endswith(".csv")]
    return csv_file_names

@enable_country_check
@enable_country_category_check
def read_csv_file_content(country,category):
    storage_client=storage.Client()
    bucket_name=get_app_configs().get(ESM_GCS_BUCKET)
    ns=get_app_configs().get(NAMESPACE)
    blob_prefix=f"ltvo_{ns}/na/{country}/{category}"
    bucket = storage_client.bucket(bucket_name)
    blobs=list(bucket.list_blobs(prefix=blob_prefix))
    csv_file_names=[blob.name for blob in blobs if blob.name.lower().endswith(".csv")]
    for csv_file in csv_file_names:
        print(f"\nProcessing CSV file:{csv_file}")
        file = bucket.blob(csv_file)
        if file.exists():
            print("File Exists")
        else:
            print("File Doesnot exists")
        try:
            blob_name=csv_file
            blob = bucket.blob(blob_name)
            rows = blob.download_as_bytes().decode().splitlines()
            rows_list=list(csv.reader(rows))
            print(list(csv.reader(rows)))
            print(rows_list[0])
            header = rows[0].split(',')
            data_list = []
            for row in rows[1:]:
                row_values = row.split(',')
                data_dict = {header[i]: row_values[i] for i in range(len(header))}
                data_list.append({"template":data_dict})
            print(data_list)
            json_data = json.dumps(data_list, indent=2)
            return json_data
        except Exception as e:
            print(f"Exception is {str(e)}")




class CostFileNameResource(Resource):
    def get(self):
        try:
            args=request.args 
            country=args.get('country')
            category=args.get('category')
            # if not country or not category:
            #     return {"error":"Missing Required parameters"}, 400
            # bucket_name="test_bucket"
            # if not bucket_name:
            #     return {"error":"bucket_name is not set"}, 500
            file_names=get_csv_file_names(country,category)
            return {"file_names":file_names}
        except Exception as e:
            return {"error":str(e)}, 500

class CostFileContentResource(Resource):
    def get(self):
        try:
            args=request.args 
            country=args.get('country')
            category=args.get('category')
            # if not country or not category:
            #     return {"error":"Missing Required parameters"}, 400
            # bucket_name="test_bucket"
            # if not bucket_name:
            #     return {"error":"bucket_name is not set"}, 500
            file_content=read_csv_file_content(country,category)
            return file_content
        except Exception as e:
            return {"error":str(e)}, 500


api.add_resource(CostFileResource, '/api/v2/cost_file')
api.add_resource(CostFileNameResource, '/api/v2/cost_file_names')




import unittest
from unittest.mock import patch, MagicMock
from your_module import get_csv_file_names, read_csv_file_content, CostFileNameResource, CostFileContentResource

class TestYourModule(unittest.TestCase):

    @patch('your_module.storage.Client')
    @patch('your_module.get_app_configs')
    def test_get_csv_file_names(self, mock_get_app_configs, mock_storage_client):
        mock_get_app_configs.return_value = {'ESM_GCS_BUCKET': 'your_bucket', 'NAMESPACE': 'your_namespace'}
        mock_bucket = MagicMock()
        mock_storage_client.return_value.bucket.return_value = mock_bucket
        mock_blob1 = MagicMock(name='blob1', name='path/to/your_file1.csv')
        mock_blob2 = MagicMock(name='blob2', name='path/to/your_file2.csv')
        mock_bucket.list_blobs.return_value = [mock_blob1, mock_blob2]

        result = get_csv_file_names('your_country', 'your_category')

        self.assertEqual(result, ['path/to/your_file1.csv', 'path/to/your_file2.csv'])

    @patch('your_module.storage.Client')
    @patch('your_module.get_app_configs')
    def test_read_csv_file_content(self, mock_get_app_configs, mock_storage_client):
        mock_get_app_configs.return_value = {'ESM_GCS_BUCKET': 'your_bucket', 'NAMESPACE': 'your_namespace'}
        mock_bucket = MagicMock()
        mock_storage_client.return_value.bucket.return_value = mock_bucket
        mock_blob = MagicMock()
        mock_blob.download_as_bytes.return_value.decode.return_value = 'header1,header2\nvalue1,value2'
        mock_bucket.blob.return_value = mock_blob









from google.cloud import storage
import json
import pandas as pd
storage_client=storage.Client()
import csv
from get_appconstants import dev_configs
def get_csv_file_content(country,category,filename):
    storage_client=storage.Client()
    bucket_name=dev_configs.get('bucket_name')
    ns=dev_configs.get('ns')
    print(f"Bucket_name is {bucket_name}")
    print(f"Namespace is {ns}")
    blob_prefix=f"ltvo_{ns}/na/{country}/{category}"
    print(f"File path is {blob_prefix}")
    bucket = storage_client.bucket(bucket_name)
    blobs=list(bucket.list_blobs(prefix=blob_prefix))
    csv_file_names=[blob.name.split("/")[-1] for blob in blobs if blob.name.lower().endswith(".csv")]
    final_csv_files=[{"csv_file_name":csv_file}for csv_file in csv_file_names]
    return final_csv_files
country=input("Enter Country name")
category = input("Enter Category name")
file_name=input("Enter Csv_file name")
csv_file_names=get_csv_file_names(country,category,file_name)
print(csv_file_names)

        result = read_csv_file_content('your_country', 'your_category')

        expected_result = '[{"template": {"header1": "value1", "header2": "value2"}}]'
        self.assertEqual(result, expected_result)

    def test_cost_file_name_resource(self):
        resource = CostFileNameResource()
        with patch.object(resource, 'get', return_value={'file_names': ['file1.csv', 'file2.csv']}):
            response = resource.get()
        self.assertEqual(response, {'file_names': ['file1.csv', 'file2.csv']})

    def test_cost_file_content_resource(self):
        resource = CostFileContentResource()
        with patch.object(resource, 'get', return_value='{"template": {"header1": "value1", "header2": "value2"}}'):
            response = resource.get()
        self.assertEqual(response, '{"template": {"header1": "value1", "header2": "value2"}}')

if __name__ == '__main__':
    unittest.main()


[
  {
    "name": "subash",
    "age": "23",
    "gender": "male"
  }
]
[
  {
    "name": "subash",
    "age": "23",
    "gender": "male"
  }
]


from google.cloud import storage
import json
import pandas as pd
storage_client=storage.Client()
import csv
from get_appconstants import dev_configs
def get_csv_file_content(country,category,filename):
    storage_client=storage.Client()
    bucket_name=dev_configs.get('bucket_name')
    ns=dev_configs.get('ns')
    print(f"Bucket_name is {bucket_name}")
    print(f"Namespace is {ns}")
    blob_prefix=f"ltvo_{ns}/na/{country}/{category}"
    print(f"File path is {blob_prefix}")
    bucket = storage_client.bucket(bucket_name)
    blobs=list(bucket.list_blobs(prefix=blob_prefix))
    csv_file_names=[blob.name.split("/")[-1] for blob in blobs if blob.name.lower().endswith(".csv")]
    final_csv_files=[{"csv_file_name":csv_file}for csv_file in csv_file_names]
    print(final_csv_files)
    print(file_name in csv_file_names)
    try:
        if file_name in csv_file_names:
            blob_name=f"ltvo_{ns}/na/{country}/{category}"+"/"+file_name
            print(blob_name)
            blob = bucket.blob(blob_name)
            rows = blob.download_as_bytes().decode().splitlines()
            rows_list=list(csv.reader(rows))
            print(list(csv.reader(rows)))
            print(rows_list[0])
            header = rows[0].split(',')
            data_list = []
            for row in rows[1:]:
                row_values = row.split(',')
                data_dict = {header[i]: row_values[i] for i in range(len(header))}
                data_list.append(data_dict)
            print(data_list)
            
            # Convert the list to JSON
            # json_data = json.dumps(data_list, indent=2)
            # print(json_data)
            # return json_data
            return data_list
        else:
            print("file does not exist in bucket")
    except Exception as e:
        print(f"Exception is {str(e)}")
country=input("Enter Country name")
category = input("Enter Category name")
file_name=input("Enter Csv_file name")
csv_file_names=get_csv_file_content(country,category,file_name)
print(csv_file_names)

['name', 'age', 'gender']
[{'name': 'subash', 'age': '23', 'gender': 'male'}]
[{'name': 'subash', 'age': '23', 'gender': 'male'}]











import unittest
from unittest.mock import patch, Mock
from flask import Flask
from your_module import api, get_csv_file_names, read_csv_file_content

class TestYourAPI(unittest.TestCase):

    def setUp(self):
        self.app = Flask(__name__)
        self.app_context = self.app.app_context()
        self.app_context.push()
        self.client = self.app.test_client()

    def tearDown(self):
        self.app_context.pop()

    @patch('your_module.get_app_configs')
    @patch('your_module.storage.Client')
    def test_get_csv_file_names(self, mock_storage_client, mock_get_app_configs):
        # Mock external dependencies
        mock_storage = Mock()
        mock_bucket = Mock()
        mock_blob = Mock()
        mock_get_app_configs.return_value = {
            'ESM_GCS_BUCKET': 'test_bucket',
            'NAMESPACE': 'test_namespace'
        }
        mock_storage_client.return_value = mock_storage
        mock_storage.bucket.return_value = mock_bucket
        mock_bucket.list_blobs.return_value = [mock_blob]
        mock_blob.name = 'test_file.csv'

        # Mock actual file content
        mock_blob.download_as_bytes.return_value = b'file_content'

        result = get_csv_file_names('us', 'category')

        # Assert that the application logic is correct
        self.assertEqual(result, ['test_file.csv'])
        mock_storage_client.assert_called_once()
        mock_storage.bucket.assert_called_once_with('test_bucket')
        mock_bucket.list_blobs.assert_called_once_with(prefix='ltvo_test_namespace/na/us/category')
        mock_blob.download_as_bytes.assert_not_called()

    @patch('your_module.storage.Client')
    def test_read_csv_file_content(self, mock_storage_client):
        # Mock external dependencies
        mock_storage = Mock()
        mock_bucket = Mock()
        mock_blob = Mock()
        mock_storage_client.return_value = mock_storage
        mock_storage.bucket.return_value = mock_bucket
        mock_bucket.list_blobs.return_value = [mock_blob]
        mock_blob.name = 'test_file.csv'

        # Mock actual file content
        mock_blob.exists.return_value = True
        mock_blob.download_as_bytes.return_value = b'header1,header2\nvalue1,value2'

        result = read_csv_file_content('us', 'category')

        # Assert that the application logic is correct
        self.assertEqual(result, '[{"template": {"header1": "value1", "header2": "value2"}}]')
        mock_storage_client.assert_called_once()
        mock_storage.bucket.assert_called_once_with('test_bucket')
        mock_bucket.list_blobs.assert_called_once_with(prefix='ltvo_test_namespace/na/us/category')
        mock_blob.download_as_bytes.assert_called_once()

if __name__ == '__main__':
    unittest.main()




import unittest
from unittest.mock import patch, Mock
from flask import Flask
from your_module import api, get_csv_file_names, read_csv_file_content

class TestYourAPI(unittest.TestCase):

    @patch('your_module.get_app_configs')
    @patch('your_module.storage.Client')
    def test_get_csv_file_names(self, mock_storage_client, mock_get_app_configs):
        # Test when files exist
        mock_storage = Mock()
        mock_bucket = Mock()
        mock_blob = Mock()
        mock_get_app_configs.return_value = {
            'ESM_GCS_BUCKET': 'test_bucket',
            'NAMESPACE': 'test_namespace'
        }
        mock_storage_client.return_value = mock_storage
        mock_storage.bucket.return_value = mock_bucket
        mock_bucket.list_blobs.return_value = [mock_blob]
        mock_blob.name = 'test_file.csv'
        mock_blob.download_as_bytes.return_value = b'file_content'

        result = get_csv_file_names('us', 'category')

        self.assertEqual(result, ['test_file.csv'])

        # Test when no files exist
        mock_bucket.list_blobs.return_value = []
        result = get_csv_file_names('us', 'category')

        self.assertEqual(result, [])

    @patch('your_module.storage.Client')
    def test_read_csv_file_content(self, mock_storage_client):
        # Test when file exists
        mock_storage = Mock()
        mock_bucket = Mock()
        mock_blob = Mock()
        mock_storage_client.return_value = mock_storage
        mock_storage.bucket.return_value = mock_bucket
        mock_bucket.list_blobs.return_value = [mock_blob]
        mock_blob.name = 'test_file.csv'
        mock_blob.exists.return_value = True
        mock_blob.download_as_bytes.return_value = b'header1,header2\nvalue1,value2'

        result = read_csv_file_content('us', 'category')

        self.assertEqual(result, '[{"template": {"header1": "value1", "header2": "value2"}}]')

        # Test when file does not exist
        mock_blob.exists.return_value = False
        result = read_csv_file_content('us', 'category')

        self.assertEqual(result, 'File Doesnot exists')

    @patch('your_module.get_app_configs')
    @patch('your_module.storage.Client')
    def test_get_csv_file_names_missing_configs(self, mock_storage_client, mock_get_app_configs):
        # Test when app configs are missing
        mock_get_app_configs.return_value = {}
        result = get_csv_file_names('us', 'category')

        self.assertEqual(result, [])  # Assuming it returns an empty list on missing configs

    @patch('your_module.storage.Client')
    def test_read_csv_file_content_exception(self, mock_storage_client):
        # Test when an exception occurs during file content reading
        mock_storage = Mock()
        mock_bucket = Mock()
        mock_blob = Mock()
        mock_storage_client.return_value = mock_storage
        mock_storage.bucket.return_value = mock_bucket
        mock_bucket.list_blobs.return_value = [mock_blob]
        mock_blob.name = 'test_file.csv'
        mock_blob.exists.return_value = True
        mock_blob.download_as_bytes.side_effect = Exception('Simulated error')

        result = read_csv_file_content('us', 'category')

        self.assertEqual(result, 'Exception is Simulated error')

    # Additional test cases...

    @patch('your_module.storage.Client')
    def test_read_csv_file_content_empty_file(self, mock_storage_client):
        # Test when the file is empty
        mock_storage = Mock()
        mock_bucket = Mock()
        mock_blob = Mock()
        mock_storage_client.return_value = mock_storage
        mock_storage.bucket.return_value = mock_bucket
        mock_bucket.list_blobs.return_value = [mock_blob]
        mock_blob.name = 'test_file.csv'
        mock_blob.exists.return_value = True
        mock_blob.download_as_bytes.return_value = b''

        result = read_csv_file_content('us', 'category')

        self.assertEqual(result, 'Empty file content')

    @patch('your_module.storage.Client')
    def test_read_csv_file_content_invalid_csv(self, mock_storage_client):
        # Test when the file contains invalid CSV
        mock_storage = Mock()
        mock_bucket = Mock()
        mock_blob = Mock()
        mock_storage_client.return_value = mock_storage
        mock_storage.bucket.return_value = mock_bucket
        mock_bucket.list_blobs.return_value = [mock_blob]
        mock_blob.name = 'test_file.csv'
        mock_blob.exists.return_value = True
        mock_blob.download_as_bytes.return_value = b'header1,header2\nvalue1'

        result = read_csv_file_content('us', 'category')

        self.assertEqual(result, 'Invalid CSV format')

if __name__ == '__main__':
    unittest.main()


Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\10722751\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
test_cost_file_service.py:1: in <module>
    from services.cost_file_service import get_csv_file_names,read_csv_file_content
..\..\services\cost_file_service.py:7: in <module>
    from google.cloud import storage
E   ImportError: cannot import name 'storage' from 'google.cloud' (unknown location)

@patch('services.cost_file_service.get_app_configs')
@patch('services.cost_file_service.storage.Client')
def test_get_csv_file_names(self, mock_storage_client, mock_get_app_configs):
        # Test when files exist
    mock_storage = Mock()
    mock_bucket = Mock()
    mock_blob = Mock()
    mock_get_app_configs.return_value = {
            'ESM_GCS_BUCKET': 'test_bucket',
            'NAMESPACE': 'test_namespace'
        }
    mock_storage_client.return_value = mock_storage
    mock_storage.bucket.return_value = mock_bucket
    mock_bucket.list_blobs.return_value = [mock_blob]
    mock_blob.name = 'test_file.csv'
    mock_blob.download_as_bytes.return_value = b'file_content'

    result = get_csv_file_names('us', 'category')

    self.assertEqual(result, ['test_file.csv'])

    # Test when no files exist
    mock_bucket.list_blobs.return_value = []
    result = get_csv_file_names('us', 'category')

    self.assertEqual(result, [])




from io import BytesIO
import tempfile
import json
import http

from flask import send_file, jsonify, request
from google.cloud import storage
import pandas as pd
import openpyxl
import csv

from configs import get_app_configs
from utils.app_constants import ESM_GCS_BUCKET, ESM_GCS_BUCKET_CA,NAMESPACE
from utils.filename_generator import generate_namespaced_esm_filename_us
from utils.filename_generator import generate_namespaced_esm_filename_ca
from annotations.param_checks import enable_country_check, enable_country_category_check
import my_logger
app_logger = my_logger.configure_logger()
BUCKET_NAME = 'ltvo-dswb-prod-c423-ltvo-us-t4p8zaot'
generate_fn = {
    'USA': (ESM_GCS_BUCKET, generate_namespaced_esm_filename_us),
    'CAN': (ESM_GCS_BUCKET_CA, generate_namespaced_esm_filename_ca)
}

def download_template_as_xlsx(blob):
    blob_content = blob.download_as_bytes()
    df = pd.read_csv(BytesIO(blob_content))
    df.drop(df.columns[df.columns.str.contains('unnamed', case=False)], 
            axis=1, inplace=True)
    # download template
    with tempfile.NamedTemporaryFile(suffix=".xlsx") as temp:
        df.to_excel(temp, index=False)
        return send_file(
            temp.name, 
            as_attachment=True,  
            mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    

def download_template(country, template):
    # check if correct country was provided
    if country not in generate_fn: 
        return {
            'message': f"Country {country} not supported."
        }, http.HTTPStatus.NOT_FOUND
    
    storage_client = storage.Client()
    bucket_name = BUCKET_NAME # param from config
    blob_name = 'ESM_STG/' + country + '/' + template + '.csv' 
    
    bucket = storage_client.get_bucket(bucket_name)
    blob = bucket.get_blob(blob_name)
    if not blob: return

    return download_template_as_xlsx(blob)


def clone_template(country, optimization_id):
    # check if correct country was provided
    if country not in generate_fn: 
        return {
            'message': f"Country {country} not supported."
        }, http.HTTPStatus.NOT_FOUND
    
    storage_client = storage.Client()
    bucket_name = get_app_configs().get(generate_fn[country][0])
    blob_name = generate_fn[country][1](optimization_id)

    bucket = storage_client.get_bucket(bucket_name)
    blob = bucket.get_blob(blob_name)
    if not blob: return

    return download_template_as_xlsx(blob)    

    
def upload_template(file, country, optimization_id):

    # check if correct country was provided
    if country not in generate_fn: 
        return {
            'message': f"Country {country} not supported."
        }, http.HTTPStatus.NOT_FOUND

    # prepare client, bucket and filename
    client = storage.Client()
    bucket = client.get_bucket(get_app_configs().get(generate_fn[country][0])) 
    filename = generate_fn[country][1](optimization_id)  

    # convert to csv
    csv_data = None
    try:
        if file.filename.endswith('.xlsx'):
            df = pd.read_excel(file, engine='openpyxl')
            csv_data = df.to_csv(index=False)
        elif file.filename.endswith('.csv'):
            df = pd.read_csv(file)
            csv_data = df.to_csv(index=False)
        else:
            return {
                "message": "Invalid file format. Send xlsx or csv."
            }, http.HTTPStatus.BAD_REQUEST
    except Exception as e:
        return {
            "message": f"Could not read the file, error: {str(e)}"
        }, http.HTTPStatus.UNPROCESSABLE_ENTITY


ERROR test_cost_file_service.py - google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Cre...
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 

    # save to a bucket
    bucket = client.get_bucket(get_app_configs().get(generate_fn[country][0]))        
    bucket.blob(filename).upload_from_string(csv_data, content_type='text/csv')

    return {
        "message": filename
    }, http.HTTPStatus.OK

# def create_anonymous_client(*args, **kwargs):
#     creds = AnonymousCredentials()
#     if _NOW() > creds.expiry:
#         creds.refresh(Request())
#     return storage.Client(credentials=creds, _http=grpc.Request())
def get_csv_file_names(country,category):
    storage_client=storage.Client()
    bucket_name=get_app_configs().get(ESM_GCS_BUCKET)
    app_logger.info(f"Bucket_name is {bucket_name}")
    ns=get_app_configs().get(NAMESPACE)
    app_logger.info(f"Namespace:{ns}")
    blob_prefix=f"ltvo_{ns}/na/{country}/{category}"
    app_logger.info(f'file path in gcs Bucket:{blob_prefix}')
    bucket = storage_client.bucket(bucket_name)
    blobs=list(bucket.list_blobs(prefix=blob_prefix))
    csv_file_names=[blob.name for blob in blobs if blob.name.lower().endswith(".csv")]
    final_csv_files=[{"csv_file_name":csv_file}for csv_file in csv_file_names]
    app_logger.info(f'final_files info:{final_csv_files}')
    return final_csv_files

@enable_country_check
@enable_country_category_check
def read_csv_file_content(country,category,file_name):
    storage_client=storage.Client()
    bucket_name=get_app_configs().get(ESM_GCS_BUCKET)
    app_logger.info(f"Bucket_name is {bucket_name}")
    ns=get_app_configs().get(NAMESPACE)
    app_logger.info(f"Namespace:{ns}")
    blob_prefix=f"ltvo_{ns}/na/{country}/{category}"
    app_logger.info(f"file path in GCS Bucket :{blob_prefix}")
    bucket = storage_client.bucket(bucket_name)
    blobs=list(bucket.list_blobs(prefix=blob_prefix))
    csv_file_names=[blob.name for blob in blobs if blob.name.lower().endswith(".csv")]
    try:
        if file_name in csv_file_names:
            blob_name=f"ltvo_{ns}/na/{country}/{category}"+"/"+file_name
            app_logger.info(f"file path for specified file:{blob_name}")
            blob = bucket.blob(blob_name)
            rows = blob.download_as_bytes().decode().splitlines()
            rows_list=list(csv.reader(rows))
            app_logger.info(f"list of rows in csv file:{list(csv.reader(rows))}")
            app_logger.info(f"List of rows in the csv file:{rows_list[0]}")
            header = rows[0].split(',')
            app_logger.info(f"Headers in the csv file:{header}")
            data_list = []
            for row in rows[1:]:
                row_values = row.split(',')
                data_dict = {header[i]: row_values[i] for i in range(len(header))}
                data_list.append(data_dict)
                app_logger.info(f"final_data{data_list}")
                #Convert the list to JSON
                json_data = json.dumps(data_list, indent=2)
                app_logger.info(f"Final Json Data is :{json_data}")
                return json_data
        else:
                return f"Filename{file_name} doesnot exist in {bucket_name}"
    except Exception as e:
        return f"Exception is {str(e)}"



import unittest
from unittest.mock import patch, Mock
from services import cost_file_service  # Assuming 'cost_file_service' is the correct module name

class TestCostFileService(unittest.TestCase):

    @patch('services.cost_file_service.get_app_configs')
    @patch('services.cost_file_service.storage.Client')
    def test_get_csv_file_names(self, mock_storage_client, mock_get_app_configs):
        mock_storage = Mock()
        mock_bucket = Mock()
        mock_blob = Mock()

        mock_get_app_configs.return_value = {
            'ESM_GCS_BUCKET': 'test_bucket',
            'NAMESPACE': 'test_namespace'
        }
        mock_storage_client.return_value = mock_storage
        mock_storage.bucket.return_value = mock_bucket
        mock_bucket.list_blobs.return_value = [mock_blob]
        mock_blob.name = 'test_file.csv'

        result = cost_file_service.get_csv_file_names('us', 'category')

        self.assertEqual(result, [{'csv_file_name': 'test_file.csv'}])

    @patch('services.cost_file_service.storage.Client')
    def test_read_csv_file_content(self, mock_storage_client):
        mock_storage = Mock()
        mock_bucket = Mock()
        mock_blob = Mock()

        mock_storage_client.return_value = mock_storage
        mock_storage.bucket.return_value = mock_bucket
        mock_bucket.list_blobs.return_value = [mock_blob]
        mock_blob.name = 'test_file.csv'
        mock_blob.download_as_bytes.return_value = b'header1,header2\nvalue1,value2'

        result = cost_file_service.read_csv_file_content('us', 'category', 'test_file.csv')

        expected_result = '[{"header1": "value1", "header2": "value2"}]'
        self.assertEqual(result, expected_result)

    @patch('services.cost_file_service.storage.Client')
    def test_read_csv_file_content_nonexistent_file(self, mock_storage_client):
        mock_storage = Mock()
        mock_bucket = Mock()
        mock_blob = Mock()

        mock_storage_client.return_value = mock_storage
        mock_storage.bucket.return_value = mock_bucket
        mock_bucket.list_blobs.return_value = [mock_blob]
        mock_blob.name = 'nonexistent_file.csv'

        result = cost_file_service.read_csv_file_content('us', 'category', 'nonexistent_file.csv')

        expected_result = 'Filename nonexistent_file.csv does not exist in test_bucket'
        self.assertEqual(result, expected_result)

if __name__ == '__main__':
    unittest.main()




# tests/test_your_module.py
import unittest
from unittest.mock import patch, Mock

# Mock the google.cloud import statement
with patch('your_module.storage.Client', Mock()), \
     patch('your_module.storage.Blob', Mock()):
    from your_module import app, get_csv_file_names, read_csv_file_content

class TestCostFileNameResource(unittest.TestCase):

    def setUp(self):
        self.app = app.test_client()

    @patch('your_module.get_csv_file_names')
    def test_get_file_names_success(self, mock_get_csv_file_names):
        mock_get_csv_file_names.return_value = ['file1.csv', 'file2.csv']

        response = self.app.get('/api/v2/cost_file_names?country=US&category=Sales')

        mock_get_csv_file_names.assert_called_once_with('US', 'Sales')
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.get_json(), {'file_names': ['file1.csv', 'file2.csv']})

    def test_get_file_names_missing_params(self):
        response = self.app.get('/api/v2/cost_file_names')
        self.assertEqual(response.status_code, 400)
        self.assertEqual(response.get_json(), {'error': 'Missing Required parameters'})

class TestCostFileContentResource(unittest.TestCase):

    def setUp(self):
        self.app = app.test_client()

    @patch('your_module.read_csv_file_content')
    def test_get_file_content_success(self, mock_read_csv_file_content):
        mock_read_csv_file_content.return_value = '{"template": [{"header1": "value1", "header2": "value2"}]}'

        response = self.app.get('/api/v2/cost_file?country=US&category=Sales')

        mock_read_csv_file_content.assert_called_once_with('US', 'Sales')
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.get_data(as_text=True), '{"template": [{"header1": "value1", "header2": "value2"}]}')

    def test_get_file_content_missing_params(self):
        response = self.app.get('/api/v2/cost_file')
        self.assertEqual(response.status_code, 400)
        self.assertEqual(response.get_json(), {'error': 'Missing Required parameters'})

    @patch('your_module.storage.Client')
    @patch('your_module.storage.Blob')
    def test_read_csv_file_content(self, mock_storage_blob, mock_storage_client):
        # Add test logic for checking file existence and reading CSV content
        mock_blob_instance = mock_storage_blob.return_value
        mock_blob_instance.exists.return_value = True
        mock_blob_instance.download_as_bytes.return_value = b'header1,header2\nvalue1,value2'

        mock_client_instance = mock_storage_client.return_value
        mock_client_instance.bucket.return_value.blob.return_value = mock_blob_instance

        result = read_csv_file_content('US', 'Sales')

        self.assertEqual(result, '[{"template": {"header1": "value1", "header2": "value2"}}]')

if __name__ == '__main__':
    unittest.main()



@patch('services.cost_file_service.get_csv_file_names',return_value=[{'csv_file_name': 'test_file.csv'}])
def test_get_csv_file_names(self, mock_storage_client:Mock):
    result = cost_file_service.get_csv_file_names('us', 'category')
    mock_storage_client.assert_called_once_with('us','fhc')
    mock_storage_client.assert_called_once()
    expected=[{'csv_file_name': 'test_file.csv'}]
    #self.assertEqual(result, [{'csv_file_name': 'test_file.csv'}])
    with app.test_client() as test_client:
            # Act
            response = test_client.get('/api/v2/cost_file')
            # Assert
            assert response.status_code == 200
            assert response.json == expected

ERROR test_cost_file_service.py - google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Cre...
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 
================================================ 1 warning, 1 error in 10.08s =============================================





import unittest
from unittest.mock import Mock, patch
from your_module import get_csv_file_names  # Replace 'your_module' with the actual module name

class TestGetCsvFileNames(unittest.TestCase):

    @patch("your_module.storage.Client")
    @patch("your_module.get_app_configs")
    @patch("your_module.app_logger")
    def test_get_csv_file_names(self, mock_logger, mock_get_app_configs, mock_storage_client):
        # Mocking necessary objects
        mock_bucket = Mock()
        mock_blobs = [Mock(name="file1.csv"), Mock(name="file2.csv")]

        mock_get_app_configs.return_value = {
            "ESM_GCS_BUCKET": "your_bucket",
            "NAMESPACE": "your_namespace"
        }

        mock_storage_client.return_value.bucket.return_value = mock_bucket
        mock_bucket.list_blobs.return_value = mock_blobs

        # Call the function with test data
        result = get_csv_file_names("US", "category")

        # Assertions
        mock_logger.info.assert_called_with("Bucket_name is your_bucket")
        mock_logger.info.assert_called_with("Namespace:your_namespace")
        mock_logger.info.assert_called_with("file path in gcs Bucket:ltvo_your_namespace/na/US/category")
        mock_logger.info.assert_called_with('final_files info:[{"csv_file_name": "file1.csv"}, {"csv_file_name": "file2.csv"}]')

        expected_result = [{"csv_file_name": "file1.csv"}, {"csv_file_name": "file2.csv"}]
        self.assertEqual(result, expected_result)

    @patch("your_module.storage.Client")
    @patch("your_module.get_app_configs")
    @patch("your_module.app_logger")
    def test_get_csv_file_names_no_csv_files(self, mock_logger, mock_get_app_configs, mock_storage_client):
        # Mocking necessary objects
        mock_bucket = Mock()
        mock_blobs = [Mock(name="other_file.txt"), Mock(name="image.png")]

        mock_get_app_configs.return_value = {
            "ESM_GCS_BUCKET": "your_bucket",
            "NAMESPACE": "your_namespace"
        }

        mock_storage_client.return_value.bucket.return_value = mock_bucket
        mock_bucket.list_blobs.return_value = mock_blobs

        # Call the function with test data
        result = get_csv_file_names("US", "category")

        # Assertions
        mock_logger.info.assert_called_with("Bucket_name is your_bucket")
        mock_logger.info.assert_called_with("Namespace:your_namespace")
        mock_logger.info.assert_called_with("file path in gcs Bucket:ltvo_your_namespace/na/US/category")
        mock_logger.info.assert_called_with('final_files info:[]')

        expected_result = []
        self.assertEqual(result, expected_result)

    @patch("your_module.storage.Client")
    @patch("your_module.get_app_configs")
    @patch("your_module.app_logger")
    def test_get_csv_file_names_no_bucket(self, mock_logger, mock_get_app_configs, mock_storage_client):
        # Mocking necessary objects
        mock_get_app_configs.return_value = {
            "ESM_GCS_BUCKET": "nonexistent_bucket",
            "NAMESPACE": "your_namespace"
        }

        mock_storage_client.return_value.bucket.side_effect = Exception("Bucket not found")

        # Call the function with test data
        result = get_csv_file_names("US", "category")

        # Assertions
        mock_logger.error.assert_called_with("Error accessing GCS bucket: Bucket not found")

        expected_result = []
        self.assertEqual(result, expected_result)

if __name__ == '__main__':
    unittest.main()






















@patch("your_module.get_app_configs")
    @patch("your_module.app_logger")
    def test_get_csv_file_names_mocked_function(self, mock_logger, mock_get_app_configs):
        # Mocking necessary objects
        mock_bucket = MagicMock()
        mock_blobs = [MagicMock(name="file1.csv"), MagicMock(name="file2.csv")]

        mock_get_app_configs.return_value = {
            "ESM_GCS_BUCKET": "your_bucket",
            "NAMESPACE": "your_namespace"
        }

        # Mocking the get_csv_file_names function
        with patch("your_module.get_csv_file_names") as mock_get_csv_file_names:
            mock_get_csv_file_names.return_value = [{"csv_file_name": "mocked_file.csv"}]

            # Call the function with test data
            result = get_csv_file_names("US", "category")

            # Assertions
            mock_logger.info.assert_called_with("Bucket_name is your_bucket")
            mock_logger.info.assert_called_with("Namespace:your_namespace")
            mock_logger.info.assert_called_with("file path in gcs Bucket:ltvo_your_namespace/na/US/category")
            mock_logger.info.assert_called_with('final_files info:[{"csv_file_name": "mocked_file.csv"}]')

            expected_result = [{"csv_file_name": "mocked_file.csv"}]
            self.assertEqual(result, expected_result)
