UI will pass a path such as “/na/usa/fhc”

Syntax for the path is /na/{country}/{category} This syntax will match the syntax of where the files are located in the COST bucket

API will return the list of files located in the GCS cost bucket with the above path.

Path in GCS should be namespaced by environment. For example, DEV should have a prefix of /dev/na/usa/fhc

Pass (Category and country) and retrieve the list of tempelate

Array of string

JSON format

Below is the confluence link



GET COST FILE
UI will pass a path such as “/na/usa/fhc/FHC_UNCONSTRAINED”

syntax is /na/{country}/{category}/{template}

API must validate the user has access to the country / category for which they are calling the endpoint. Can use legacy API functionality for this validation.

API must return the json list of deals that are in the csv file at the above path


gcp_storage:
    image: oittaa/gcp-storage-emulator
    container_name: gcp_storage
    ports:
      - "9023:9023"
    environment:
      PORT: 9023
      HOST: gcp_storage
    volumes:
      - gcp-data:/storage



 source_blob = storage_client.list_blobs(bucket, prefix=prefix, delimiter="/")
        copied_list = []
        for blob in source_blob:
            if blob.name.endswith(".csv"):
                source_bucket.copy_blob(blob, destination_bucket, dest_path + blob.name.split("/")[-1])
                copied_list.append({"file_copied" : bucket + "/"+ dest_path + blob.name.split("/")[-1]})
        return copied_list

BUCKET_NAME = 'ltvo-dswb-prod-c423-ltvo-us-t4p8zaot'
if country not in generate_fn: 
        return {
            'message': f"Country {country} not supported."
        }, http.HTTPStatus.NOT_FOUND
    
    storage_client = storage.Client()
    bucket_name = BUCKET_NAME # param from config
    blob_name = 'ESM_STG/' + country + '/' + template + '.csv' 
    
    bucket = storage_client.get_bucket(bucket_name)
    blob = bucket.get_blob(blob_name)
    if not blob: return



import os
from google.cloud import storage
from flask import Flask, request, jsonify

app = Flask(__name__)

def get_file_names(country, template):
    # Get the bucket name from the environment variable
    bucket_name = os.environ.get('GCS_BUCKET_NAME')

    if not bucket_name:
        return {"error": "GCS_BUCKET_NAME environment variable not set."}

    storage_client = storage.Client()

    # Construct the blob prefix
    blob_prefix = f'ESM_STG/{country}/{template}/'

    # Get the bucket
    bucket = storage_client.bucket(bucket_name)

    # List blobs in the bucket with the specified prefix
    blobs = list(bucket.list_blobs(prefix=blob_prefix))

    file_names = [blob.name.split("/")[-1] for blob in blobs]

    return file_names

@app.route('/get_file_names', methods=['GET'])
def get_file_names_endpoint():
    try:
        # Get parameters from the request
        country = request.args.get('country')
        template = request.args.get('template')

        # Check if required parameters are provided
        if not country or not template:
            return jsonify({"error": "Missing required parameters."}), 400

        # Get file names from the GCS path
        file_names = get_file_names(country, template)

        return jsonify({"file_names": file_names})

    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
