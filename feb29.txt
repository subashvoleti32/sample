from sqlalchemy import create_engine, Column, Integer, String, Date, ForeignKey
from sqlalchemy.orm import relationship, backref
from sqlalchemy.ext.declarative import declarative_base

# Define the SQLAlchemy engine
engine = create_engine('sqlite:///pizza_ordering.db', echo=True)

# Define the declarative base
Base = declarative_base()

# Define the SQLAlchemy models with relationships
class Pizza(Base):
    __tablename__ = 'pizzas'
    pizza_id = Column(Integer, primary_key=True)
    pizza_name = Column(String)
    pizza_type = Column(String)
    pizza_description = Column(String)
    orders = relationship("Order", back_populates="pizza")

class Order(Base):
    __tablename__ = 'orders'
    order_id = Column(Integer, primary_key=True)
    order_customer_id = Column(Integer, ForeignKey('customers.customer_id'))
    order_type = Column(String)
    order_number = Column(String)
    order_description = Column(String)
    customer = relationship("Customer", back_populates="orders")
    pizza_id = Column(Integer, ForeignKey('pizzas.pizza_id'))
    pizza = relationship("Pizza", back_populates="orders")
    statuses = relationship("OrderStatus", back_populates="order")

class Customer(Base):
    __tablename__ = 'customers'
    customer_id = Column(Integer, primary_key=True)
    customer_name = Column(String)
    customer_mobile = Column(String)
    customer_email = Column(String)
    customer_username = Column(String)
    customer_password = Column(String)
    customer_address = Column(String)
    orders = relationship("Order", back_populates="customer")
    payments = relationship("Payment", back_populates="customer")

class OrderStatus(Base):
    __tablename__ = 'order_statuses'
    status_id = Column(Integer, primary_key=True)
    status_order_id = Column(Integer, ForeignKey('orders.order_id'))
    status_name = Column(String)
    status_update = Column(String)
    status_time = Column(String)
    status_date = Column(Date)
    status_type = Column(String)
    status_description = Column(String)
    order = relationship("Order", back_populates="statuses")

class Coupon(Base):
    __tablename__ = 'coupons'
    coupon_id = Column(Integer, primary_key=True)
    coupon_pizza_id = Column(Integer, ForeignKey('pizzas.pizza_id'))
    coupon_name = Column(String)
    coupon_type = Column(String)
    coupon_description = Column(String)

class Payment(Base):
    __tablename__ = 'payments'
    payment_id = Column(Integer, primary_key=True)
    payment_customer_id = Column(Integer, ForeignKey('customers.customer_id'))
    payment_date = Column(Date)
    payment_amount = Column(Integer)
    payment_description = Column(String)
    customer = relationship("Customer", back_populates="payments")

# Create the tables in the database
Base.metadata.create_all(engine)




# CRUD operations for Pizza
@app.post("/pizzas/", response_model=Pizza)
def create_pizza(pizza: Pizza, db: Session = Depends(get_db)):
    db.add(pizza)
    db.commit()
    db.refresh(pizza)
    return pizza

@app.get("/pizzas/", response_model=List[Pizza])
def read_pizzas(skip: int = 0, limit: int = 10, db: Session = Depends(get_db)):
    return db.query(Pizza).offset(skip).limit(limit).all()

@app.get("/pizzas/{pizza_id}", response_model=Pizza)
def read_pizza(pizza_id: int, db: Session = Depends(get_db)):
    return db.query(Pizza).filter(Pizza.pizza_id == pizza_id).first()

@app.put("/pizzas/{pizza_id}", response_model=Pizza)
def update_pizza(pizza_id: int, pizza: Pizza, db: Session = Depends(get_db)):
    db_pizza = db.query(Pizza).filter(Pizza.pizza_id == pizza_id).first()
    for var, value in vars(pizza).items():
        setattr(db_pizza, var, value)
    db.commit()
    db.refresh(db_pizza)
    return db_pizza

@app.delete("/pizzas/{pizza_id}")
def delete_pizza(pizza_id: int, db: Session = Depends(get_db)):
    db.query(Pizza).filter(Pizza.pizza_id == pizza_id).delete(synchronize_session=False)
    db.commit()
    return {"message": "Pizza deleted successfully"}


# CRUD operations for Order
@app.post("/orders/", response_model=Order)
def create_order(order: Order, db: Session = Depends(get_db)):
    db.add(order)
    db.commit()
    db.refresh(order)
    return order

@app.get("/orders/", response_model=List[Order])
def read_orders(skip: int = 0, limit: int = 10, db: Session = Depends(get_db)):
    return db.query(Order).offset(skip).limit(limit).all()

@app.get("/orders/{order_id}", response_model=Order)
def read_order(order_id: int, db: Session = Depends(get_db)):
    return db.query(Order).filter(Order.order_id == order_id).first()

@app.put("/orders/{order_id}", response_model=Order)
def update_order(order_id: int, order: Order, db: Session = Depends(get_db)):
    db_order = db.query(Order).filter(Order.order_id == order_id).first()
    for var, value in vars(order).items():
        setattr(db_order, var, value)
    db.commit()
    db.refresh(db_order)
    return db_order

@app.delete("/orders/{order_id}")
def delete_order(order_id: int, db: Session = Depends(get_db)):
    db.query(Order).filter(Order.order_id == order_id).delete(synchronize_session=False)
    db.commit()
    return {"message": "Order deleted successfully"}


# CRUD operations for Customer
@app.post("/customers/", response_model=Customer)
def create_customer(customer: Customer, db: Session = Depends(get_db)):
    db.add(customer)
    db.commit()
    db.refresh(customer)
    return customer

@app.get("/customers/", response_model=List[Customer])
def read_customers(skip: int = 0, limit: int = 10, db: Session = Depends(get_db)):
    return db.query(Customer).offset(skip).limit(limit).all()

@app.get("/customers/{customer_id}", response_model=Customer)
def read_customer(customer_id: int, db: Session = Depends(get_db)):
    return db.query(Customer).filter(Customer.customer_id == customer_id).first()

@app.put("/customers/{customer_id}", response_model=Customer)
def update_customer(customer_id: int, customer: Customer, db: Session = Depends(get_db)):
    db_customer = db.query(Customer).filter(Customer.customer_id == customer_id).first()
    for var, value in vars(customer).items():
        setattr(db_customer, var, value)
    db.commit()
    db.refresh(db_customer)
    return db_customer

@app.delete("/customers/{customer_id}")
def delete_customer(customer_id: int, db: Session = Depends(get_db)):
    db.query(Customer).filter(Customer.customer_id == customer_id).delete(synchronize_session=False)
    db.commit()
    return {"message": "Customer deleted successfully"}


# CRUD operations for OrderStatus
@app.post("/order_statuses/", response_model=OrderStatus)
def create_order_status(order_status: OrderStatus, db: Session = Depends(get_db)):
    db.add(order_status)
    db.commit()
    db.refresh(order_status)
    return order_status

@app.get("/order_statuses/", response_model=List[OrderStatus])
def read_order_statuses(skip: int = 0, limit: int = 10, db: Session = Depends(get_db)):
    return db.query(OrderStatus).offset(skip).limit(limit).all()

@app.get("/order_statuses/{status_id}", response_model=OrderStatus)
def read_order_status(status_id: int, db: Session = Depends(get_db)):
    return db.query(OrderStatus).filter(OrderStatus.status_id == status_id).first()

@app.put("/order_statuses/{status_id}", response_model=OrderStatus)
def update_order_status(status_id: int, order_status: OrderStatus, db: Session = Depends(get_db)):
    db_order_status = db.query(OrderStatus).filter(OrderStatus.status_id == status_id).first()
    for var, value in vars(order_status).items():
        setattr(db_order_status, var, value)
    db.commit()
    db.refresh(db_order_status)
    return db_order_status

@app.delete("/order_statuses/{status_id}")
def delete_order_status(status_id: int, db: Session = Depends(get_db)):
    db.query(OrderStatus).filter(OrderStatus.status_id == status_id).delete(synchronize_session=False)
    db.commit()
    return {"message": "Order status deleted successfully"}


# CRUD operations for Coupon
@app.post("/coupons/", response_model=Coupon)
def create_coupon(coupon: Coupon, db: Session = Depends(get_db)):
    db.add(coupon)
    db.commit()
    db.refresh(coupon)
    return coupon

@app.get("/coupons/", response_model=List[Coupon])
def read_coupons(skip: int = 0, limit: int = 10, db: Session = Depends(get_db)):
    return db.query(Coupon).offset(skip).limit(limit).all()

@app.get("/coupons/{coupon_id}", response_model=Coupon)
def read_coupon(coupon_id: int, db: Session = Depends(get_db)):
    return db.query(Coupon).filter(Coupon.coupon_id == coupon_id).first()

@app.put("/coupons/{coupon_id}", response_model=Coupon)
def update_coupon(coupon_id: int, coupon: Coupon, db: Session = Depends(get_db)):
    db_coupon = db.query(Coupon).filter(Coupon.coupon_id == coupon_id).first()
    for var, value in vars(coupon).items():
        setattr(db_coupon, var, value)
    db.commit()
    db.refresh(db_coupon)
    return db_coupon

@app.delete("/coupons/{coupon_id}")
def delete_coupon(coupon_id: int, db: Session = Depends(get_db)):
    db.query(Coupon).filter(Coupon.coupon_id == coupon_id).delete(synchronize_session=False)
    db.commit()
    return {"message": "Coupon deleted successfully"}


# CRUD operations for Payment
@app.post("/payments/", response_model=Payment)
def create_payment(payment: Payment, db: Session = Depends(get_db)):
    db.add(payment)
    db.commit()
    db.refresh(payment)
    return payment

@app.get("/payments/", response_model=List[Payment])
def read_payments(skip: int = 0, limit: int = 10, db: Session = Depends(get_db)):
    return db.query(Payment).offset(skip).limit(limit).all()

@app.get("/payments/{payment_id}", response_model=Payment)
def read_payment(payment_id: int, db: Session = Depends(get_db)):
    return db.query(Payment).filter(Payment.payment_id == payment_id).first()

@app.put("/payments/{payment_id}", response_model=Payment)
def update_payment(payment_id: int, payment: Payment, db: Session = Depends(get_db)):
    db_payment = db.query(Payment).filter(Payment.payment_id == payment_id).first()
    for var, value in vars(payment).items():
        setattr(db_payment, var, value)
    db.commit()
    db.refresh(db_payment)
    return db_payment

@app.delete("/payments/{payment_id}")
def delete_payment(payment_id: int, db: Session = Depends(get_db)):
    db.query(Payment).filter(Payment.payment_id == payment_id).delete(synchronize_session=False)
    db.commit()
    return {"message": "Payment deleted successfully"}

def download_template_as_xlsx(blob):
    try:
        blob_content = blob.download_as_bytes()
        df = pd.read_csv(BytesIO(blob_content))
        df.drop(df.columns[df.columns.str.contains('unnamed', case=False)], 
                axis=1, inplace=True)
        # download template
        with tempfile.NamedTemporaryFile(suffix=".xlsx") as temp:
            df.to_excel(temp, index=False)
            return send_file(
                temp.name, 
                as_attachment=True,  
                mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    except Exception as e:
        return {
            "message": f"Could not able to download the file, error: {str(e)}"
        },http.HTTPStatus.FORBIDDEN
    
    

def download_template(country, template):
    # check if correct country was provided
    if country not in generate_fn: 
        return {
            'message': f"Country {country} not supported."
        }, http.HTTPStatus.NOT_FOUND
    try:
        storage_client = storage.Client()
        bucket_name = BUCKET_NAME # param from config
        blob_name = 'ESM_STG/' + country + '/' + template + '.csv' 
        
        bucket = storage_client.get_bucket(bucket_name)
        blob = bucket.get_blob(blob_name)
        if not blob: return

        return download_template_as_xlsx(blob)
    except Exception as e:
        return {
            "message": f"Could not able to download the file, error: {str(e)}"
        }, http.HTTPStatus.FORBIDDEN



# File: download_module.py
import pandas as pd
from io import BytesIO
import tempfile
from flask import send_file
from google.cloud import storage
import http

MAX_REQUEST_SIZE = 32 * 1024 * 1024  # 32 MiB
CHUNK_SIZE = 1024  # Chunk size for streaming

def download_large_template(blob):
    try:
        blob_content = blob.download_as_bytes()
        df = pd.read_csv(BytesIO(blob_content))
        df.drop(df.columns[df.columns.str.contains('unnamed', case=False)], 
                axis=1, inplace=True)
        # download template
        with tempfile.NamedTemporaryFile(suffix=".xlsx") as temp:
            df.to_excel(temp, index=False)
            return send_file(
                temp.name, 
                as_attachment=True,  
                mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                chunk_size=CHUNK_SIZE
            )
    except Exception as e:
        return {
            "message": f"Could not able to download the file, error: {str(e)}"
        }, http.HTTPStatus.FORBIDDEN

def download_normal_template(blob):
    try:
        blob_content = blob.download_as_bytes()
        df = pd.read_csv(BytesIO(blob_content))
        df.drop(df.columns[df.columns.str.contains('unnamed', case=False)], axis=1, inplace=True)
        
        # Download template
        with tempfile.NamedTemporaryFile(suffix=".xlsx") as temp:
            df.to_excel(temp, index=False)
            return send_file(
                temp.name, 
                as_attachment=True,  
                mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    except Exception as e:
        return {
            "message": f"Could not able to download the file, error: {str(e)}"
        }, http.HTTPStatus.FORBIDDEN
    
def download_template(country, template):
    # check if correct country was provided
    if country not in generate_fn: 
        return {
            'message': f"Country {country} not supported."
        }, http.HTTPStatus.NOT_FOUND
    try:
        storage_client = storage.Client()
        bucket_name = BUCKET_NAME # param from config
        blob_name = 'ESM_STG/' + country + '/' + template + '.csv' 
        
        bucket = storage_client.get_bucket(bucket_name)
        blob = bucket.get_blob(blob_name)
        if not blob: 
            return {
                'message': f"File not found for country {country} and template {template}."
            }, http.HTTPStatus.NOT_FOUND

        # Check file size
        file_size = blob.size
        if file_size > MAX_REQUEST_SIZE:
            return download_large_template(blob)
        else:
            return download_normal_template(blob)
    except Exception as e:
        return {
            "message": f"Could not able to download the file, error: {str(e)}"
        }, http.HTTPStatus.FORBIDDEN























def download_large_template(blob):
    try:
        blob_content = blob.download_as_bytes()
        df = pd.read_csv(BytesIO(blob_content))
        df.drop(df.columns[df.columns.str.contains('unnamed', case=False)], 
                axis=1, inplace=True)
        # download template
        with tempfile.NamedTemporaryFile(suffix=".xlsx") as temp:
            df.to_excel(temp, index=False)
            return send_file(
                temp.name, 
                as_attachment=True,  
                mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                chunk_size=CHUNK_SIZE
            )
    except Exception as e:
        return {
            "message": f"Could not able to download the file, error: {str(e)}"
        }, http.HTTPStatus.FORBIDDEN
def download_normal_template(blob):
    try:
        blob_content = blob.download_as_bytes()
        df = pd.read_csv(BytesIO(blob_content))
        df.drop(df.columns[df.columns.str.contains('unnamed', case=False)], axis=1, inplace=True)
        # Download template
        with tempfile.NamedTemporaryFile(suffix=".xlsx") as temp:
            df.to_excel(temp, index=False)
            return send_file(
                temp.name, 
                as_attachment=True,  
                mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    except Exception as e:
        return {
            "message": f"Could not able to download the file, error: {str(e)}"
        }, http.HTTPStatus.FORBIDDEN

def download_template(country, template):
    # check if correct country was provided
    if country not in generate_fn: 
        return {
            'message': f"Country {country} not supported."
        }, http.HTTPStatus.NOT_FOUND
    try:
        storage_client = storage.Client()
        bucket_name = BUCKET_NAME # param from config
        blob_name = 'ESM_STG/' + country + '/' + template + '.csv' 
        
        bucket = storage_client.get_bucket(bucket_name)
        blob = bucket.get_blob(blob_name)
        if not blob: 
            return {
            "message": f"File not found for country{country} and template{template}"
        },http.HTTPStatus.NOT_FOUND
        file_size=blob.size   
        if file_size>MAX_REQUEST_SIZE:
            return download_large_template(blob)
        else:
            return download_normal_template(blob)
    except Exception as e:
        return {
            "message": f"Could not able to download the file, error: {str(e)}"
        }, http.HTTPStatus.FORBIDDEN
        































import pandas as pd
from io import BytesIO
import tempfile
from flask import Flask, Response, send_file
from google.cloud import storage
import http

app = Flask(__name__)

MAX_REQUEST_SIZE = 32 * 1024 * 1024  # 32 MiB
CHUNK_SIZE = 1024  # Chunk size for streaming

def generate_excel_chunks(blob):
    blob_content = blob.download_as_bytes()
    df = pd.read_csv(BytesIO(blob_content))
    df.drop(df.columns[df.columns.str.contains('unnamed', case=False)], axis=1, inplace=True)
    
    # Download template
    with tempfile.NamedTemporaryFile(suffix=".xlsx") as temp:
        df.to_excel(temp, index=False)
        temp.seek(0)
        while True:
            chunk = temp.read(CHUNK_SIZE)
            if not chunk:
                break
            yield chunk

@app.route('/download_template/<country>/<template>')
def download_template(country, template):
    # check if correct country was provided
    if country not in generate_fn: 
        return {
            'message': f"Country {country} not supported."
        }, http.HTTPStatus.NOT_FOUND
    try:
        storage_client = storage.Client()
        bucket_name = BUCKET_NAME # param from config
        blob_name = 'ESM_STG/' + country + '/' + template + '.csv' 
        
        bucket = storage_client.get_bucket(bucket_name)
        blob = bucket.get_blob(blob_name)
        if not blob:
            return {
                'message': f"File not found for country {country} and template {template}."
            }, http.HTTPStatus.NOT_FOUND

        # Check file size
        file_size = blob.size
        if file_size > MAX_REQUEST_SIZE:
            return Response(generate_excel_chunks(blob), mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', direct_passthrough=True)

        # If the file size is within the limit, return it as a whole
        blob_content = blob.download_as_bytes()
        df = pd.read_csv(BytesIO(blob_content))
        df.drop(df.columns[df.columns.str.contains('unnamed', case=False)], axis=1, inplace=True)
        
        # Download template
        with tempfile.NamedTemporaryFile(suffix=".xlsx") as temp:
            df.to_excel(temp, index=False)
            return send_file(
                temp.name, 
                as_attachment=True,  
                mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    except Exception as e:
        return {
            "message": f"Could not able to download the file, error: {str(e)}"
        }, http.HTTPStatus.FORBIDDEN

if __name__ == "__main__":
    app.run()
----------------------------
import http
import tempfile

import pandas as pd
from flask import json
from flask import send_file
from google.cloud import storage
from tenacity import retry, retry_if_exception_type, stop_after_delay

from configs import get_app_configs, _init_session

from utils.app_constants import OUTPUT_GCS_BUCKET, OUTPUT_GCS_BUCKET_CA
from models.optimizations import Optimization
import my_logger
app_logger = my_logger.configure_logger()

def download_file(file_name):
    app_logger.info(f"download_file_name:{file_name}")
    storage_client = storage.Client()
    bucket = storage_client.get_bucket(get_app_configs().get(OUTPUT_GCS_BUCKET))
    blob = bucket.blob(file_name)
    with tempfile.NamedTemporaryFile() as temp:
        blob.download_to_filename(temp.name)
        return send_file(temp.name, attachment_filename=file_name)


def get_output_df(output_path, upper_partition, brand):
    app_logger.info(f"get_output_df args:output_path:{output_path},upper_partition:{upper_partition},brand:{brand}")
    summary_df = get_blob(bucket=get_app_configs().get(OUTPUT_GCS_BUCKET),
                          output_path=output_path,
                          file_part="base_sum_data")

    df = pd.read_csv('gs://' + get_app_configs().get(OUTPUT_GCS_BUCKET) + '/' + summary_df)
    print('df columns')
    print(df.columns)
    app_logger.info(f"df.columns:{df.columns}")
    df = df[df.lower_partition == 0]
    if upper_partition:
        df = df[df.upper_partition == upper_partition]
    if brand:
        brand = brand.replace(' ', '_')
        df = df[df.brand == brand]
    js = df.to_json(orient='records')
    # app_logger.info(f"get_output_df convert to json:{json.loads(js)}")
    return json.loads(js)


@retry(retry=retry_if_exception_type(OSError), stop=stop_after_delay(5))
def get_output_dict_values(output_path):
    print("================STARTING DICT DOWNLOAD=============")
    summary_df = get_blob(get_app_configs().get(OUTPUT_GCS_BUCKET), output_path, "base_sum_data")

    df = pd.read_csv('gs://' + get_app_configs().get(OUTPUT_GCS_BUCKET) + '/' + summary_df)
    upper_partition = df['upper_partition'].drop_duplicates().to_list()
    brand = df['brand'].drop_duplicates().to_list()
    response = json.dumps({'upper_partition': upper_partition, 'brand': brand})
    # app_logger.info(f"get_output_dict_values response:{json.loads(response)}")
    return json.loads(response)


def download_log_file(optimization_id):
    print("=====STARTING DOWNLOAD=======")
    session = _init_session()
    storage_client = storage.Client()
    bucket = storage_client.bucket(get_app_configs().get(OUTPUT_GCS_BUCKET))
    log_file_path = session.query(Optimization.log_file_path).filter_by(id=optimization_id).scalar()

    session.close()
    with tempfile.NamedTemporaryFile() as temp:
        bucket.blob(log_file_path).download_to_filename(temp.name)
        return send_file(temp.name, as_attachment=True, attachment_filename="log.txt")


def download_summary_df(output_path):
    summary_df = get_blob(bucket=get_app_configs().get(OUTPUT_GCS_BUCKET),
                          output_path=output_path,
                          file_part= "base_sum_data")

    storage_client = storage.Client()
    bucket = storage_client.get_bucket(get_app_configs().get(OUTPUT_GCS_BUCKET))
    blob = bucket.blob(summary_df)
    with tempfile.NamedTemporaryFile() as temp:
        blob.download_to_filename(temp.name)
        return send_file(temp.name, attachment_filename=summary_df)


def download_total_df(output_path):
    total_df = get_blob(bucket=get_app_configs().get(OUTPUT_GCS_BUCKET),
                        output_path=output_path,
                        file_part= "base_dtl_data")

    storage_client = storage.Client()
    bucket = storage_client.get_bucket(get_app_configs().get(OUTPUT_GCS_BUCKET))
    blob = bucket.blob(total_df)
    with tempfile.NamedTemporaryFile() as temp:
        blob.download_to_filename(temp.name)
        return send_file(temp.name, attachment_filename=total_df)


########################### TESSERACT ###########################
def download_tesseract_summary_df(output_path):
    tesseract_summary_df = get_blob(bucket=get_app_configs().get(OUTPUT_GCS_BUCKET),
                                    output_path=output_path,
                                    file_part= "tesseract_sum_data")

    storage_client = storage.Client()
    bucket = storage_client.get_bucket(get_app_configs().get(OUTPUT_GCS_BUCKET))
    blob = bucket.blob(tesseract_summary_df)
    with tempfile.NamedTemporaryFile() as temp:
        blob.download_to_filename(temp.name)
        return send_file(temp.name, attachment_filename=tesseract_summary_df)


def download_tesseract_results_df(output_path):
    tesseract_results_df = get_blob(bucket=get_app_configs().get(OUTPUT_GCS_BUCKET),
                                    output_path=output_path,
                                    file_part="tesseract_dtl_data")

    storage_client = storage.Client()
    bucket = storage_client.get_bucket(get_app_configs().get(OUTPUT_GCS_BUCKET))
    blob = bucket.blob(tesseract_results_df)
    with tempfile.NamedTemporaryFile() as temp:
        blob.download_to_filename(temp.name)
        return send_file(temp.name, attachment_filename=tesseract_results_df)


##################################################################

def get_blob_name_from_gcs(output_path, endswith):
    storage_client = storage.Client()
    blobs = storage_client.list_blobs(get_app_configs().get(OUTPUT_GCS_BUCKET), prefix=output_path, delimiter='/')

    filename = ''
    for blob in blobs:
        if blob.name.endswith(endswith):
            filename = blob.name

    # print('filename - ' + filename)
    # print('path - gs://' + get_app_configs().get(OUTPUT_GCS_BUCKET) + '/' + filename)
    app_logger.info(f"get_blob_name_from_gcs filename is{filename}")
    return filename


def get_blob_by_name_part(bucket_name, file_name):
    storage_client = storage.Client()
    blobs = storage_client.list_blobs(bucket_name)

    for blob in blobs:
        if file_name in blob.name:
            return blob

    return f'File {file_name} was not found.'


def get_blob(bucket, output_path, file_part):
    client = storage.Client()
    blobs = client.list_blobs(bucket, prefix=output_path.lstrip("/").rstrip("/"))
    result = [blob for blob in blobs if file_part in blob.name]
    if len(result) == 0:
        print("==============> NO FILE FOUND")
        return "ERROR"
    else:
        print("===============FOUND FILE(S)")
        print(result[0].name)
        app_logger.info(f"get_blob name is{result[0].name}")
        return result[0].name

def get_blob_direct_url(optimization_id, file_part):

    # Get optimization by id
    session = _init_session()
    q = session.query(Optimization).filter(Optimization.id==3213).first()
    session.close()

    # Establish bucket based on country, set variables to build url
    bucket = OUTPUT_GCS_BUCKET if q.country == 'USA' else OUTPUT_GCS_BUCKET_CA
    bucket = get_app_configs().get(bucket)
    output_path = q.output_file_path
    prefix = 'https://console.cloud.google.com/storage/browser/_details/'

    # Find the blob
    client = storage.Client()
    blobs = client.list_blobs(bucket, prefix=output_path.lstrip("/").rstrip("/"))
    blob = [blob for blob in blobs if file_part in blob.name and blob.name.endswith('csv')].pop()

    # Build URL to return
    url = prefix + bucket + '/' + blob.name
    app_logger.info(f"get_blob_direct_url :{url}")
    return url


class ExperimentOutputTotalFile(Resource):
    def get(self):
        args = request.args
        app_logger.info(f"ExperimentOutputTotalFile args:-{args}")
        country = args.get('country') if args.get('country') else None
        path = str(args.get('output_path')) if args.get('output_path') else None
        try:
            if country == "USA":
                resp = exp_output_service.download_total_df(output_path=path)
                return resp
            elif country == "CAN":
                resp = exp_output_ca_service.download_total_df(output_path=path)
                return resp
            else:
                return  {
                    "status": http.HTTPStatus.NOT_FOUND,
                    "message": "requested country recs were not found"
            }
        except BaseException as e:
            resp = []
        app_logger.info(f"ExperimentOutputTotalFileResponse:{resp}")

api.add_resource(ExperimentOutputTotalFile, '/api/v1/exp_output_total_df/')
        return resp
